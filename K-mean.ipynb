{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1d1718d-15f4-40b7-b601-3ce1c3d8c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from itertools import combinations as combo\n",
    "\n",
    "def load_and_preprocess(file_path, file_format, data_percentage):\n",
    "    def load_excel(file_path):\n",
    "        return pd.read_excel(file_path)\n",
    "    \n",
    "    def load_text(file_path):\n",
    "        return pd.read_table(file_path, sep='\\t')\n",
    "    \n",
    "    def load_csv(file_path):\n",
    "        return pd.read_csv(file_path)\n",
    "    \n",
    "    loaders = {\n",
    "        'Excel': load_excel,\n",
    "        'Text': load_text,\n",
    "        'CSV': load_csv\n",
    "    }\n",
    "    \n",
    "    if file_format not in loaders:\n",
    "        raise ValueError(\"Invalid file format. Please choose 'Excel', 'Text', or 'CSV'.\")\n",
    "    \n",
    "    df = loaders[file_format](file_path)\n",
    "    df['Items'] = df['Items'].astype(str)\n",
    "    num_records = int(len(df) * data_percentage / 100)\n",
    "    df = df.head(num_records)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_candidates(frequent_itemsets, k):\n",
    "    return {frozenset(set1 | set2) for set1 in frequent_itemsets for set2 in frequent_itemsets if len(set1 | set2) == k}\n",
    "\n",
    "\n",
    "def prune_candidates(candidates, prev_frequent_itemsets):\n",
    "    return {itemset for itemset in candidates if all(itemset - {item} in prev_frequent_itemsets for item in itemset)}\n",
    "\n",
    "\n",
    "def find_frequent_itemsets(df, min_support):\n",
    "    frequent_itemsets = {}\n",
    "    transactions = df.groupby('TransactionNo')['Items'].apply(set)\n",
    "    unique_items = {item for transaction in transactions for item in transaction}\n",
    "    \n",
    "    itemsets_size_1 = [frozenset({item}) for item in unique_items]\n",
    "    frequent_itemsets[1] = {itemset: sum(1 for transaction in transactions if itemset.issubset(transaction)) for itemset in itemsets_size_1}\n",
    "    \n",
    "    k = 2\n",
    "    while frequent_itemsets.get(k - 1):\n",
    "        candidates = prune_candidates(generate_candidates(frequent_itemsets[k - 1].keys(), k), frequent_itemsets[k - 1].keys())\n",
    "        supports = {itemset: sum(1 for transaction in transactions if itemset.issubset(transaction)) for itemset in candidates}\n",
    "        frequent_itemsets[k] = {itemset: support for itemset, support in supports.items() if support >= min_support}\n",
    "        k += 1\n",
    "    \n",
    "    frequent_itemsets = {k: v for k, v in frequent_itemsets.items() if v and any(support >= min_support for support in v.values())}\n",
    "    return frequent_itemsets\n",
    "\n",
    "def discover_association_rules(frequent_itemsets, df, min_confidence):\n",
    "    association_rules = []\n",
    "    transactions = df.groupby('TransactionNo')['Items'].apply(set)\n",
    "    for size, itemsets in frequent_itemsets.items():\n",
    "        if size > 1:\n",
    "            for itemset, support in itemsets.items():\n",
    "                for i in range(1, len(itemset)):\n",
    "                    for antecedent in combo(itemset, i):\n",
    "                        antecedent = frozenset(antecedent)\n",
    "                        consequent = itemset - antecedent\n",
    "                        if antecedent in frequent_itemsets[i]:\n",
    "                            confidence = support / frequent_itemsets[i][antecedent]\n",
    "                            if confidence >= min_confidence:\n",
    "                                association_rules.append((antecedent, consequent, confidence))\n",
    "    return association_rules\n",
    "\n",
    "\n",
    "def show_frequent_itemsets(frequent_itemsets, min_support):\n",
    "    output_text = \"Frequent Item Sets:\\n\"\n",
    "    for size in sorted(frequent_itemsets.keys()):\n",
    "        itemsets = frequent_itemsets[size]\n",
    "        for itemset, support in itemsets.items():\n",
    "            if support >= min_support:\n",
    "                output_text += \"{} - Support: {}\\n\".format(list(itemset), support)\n",
    "    return output_text\n",
    "\n",
    "\n",
    "def show_association_rules(association_rules):\n",
    "    output_text = \"\\nStrong Association Rules:\\n\"\n",
    "    for rule in association_rules:\n",
    "        antecedent, consequent, confidence = rule\n",
    "        output_text += \"{} => {} - Confidence: {:.2f}\\n\".format(list(antecedent), list(consequent), confidence)\n",
    "    return output_text\n",
    "\n",
    "def browse_file(entry):\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    entry.delete(0, tk.END)\n",
    "    entry.insert(0, file_path)\n",
    "\n",
    "def run_analysis(file_entry, format_entry, support_entry, confidence_entry, percentage_entry, output_text):\n",
    "    file_path = file_entry.get()\n",
    "    file_format = format_entry.get()\n",
    "    min_support = float(support_entry.get())\n",
    "    min_confidence = float(confidence_entry.get()) / 100\n",
    "    data_percentage = float(percentage_entry.get())\n",
    "    \n",
    "    try:\n",
    "        df = load_and_preprocess(file_path, file_format, data_percentage)\n",
    "        frequent_itemsets = find_frequent_itemsets(df, min_support)\n",
    "        association_rules = discover_association_rules(frequent_itemsets, df, min_confidence)\n",
    "        \n",
    "        frequent_output = show_frequent_itemsets(frequent_itemsets, min_support)\n",
    "        rules_output = show_association_rules(association_rules)\n",
    "        \n",
    "        output_text.config(state=tk.NORMAL)\n",
    "        output_text.delete(\"1.0\", tk.END)\n",
    "        output_text.insert(tk.END, frequent_output + \"\\n\" + rules_output)\n",
    "        output_text.config(state=tk.DISABLED)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "def create_gui():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Association Analysis Tool Using Apriori Algorithm\")\n",
    "    root.configure(background='#E8F6EF')\n",
    "    \n",
    "    file_label = tk.Label(root, text=\"File Path:\", background='#E8F6EF')\n",
    "    file_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "    file_entry = tk.Entry(root, width=50)\n",
    "    file_entry.grid(row=0, column=1, columnspan=2, padx=5, pady=5)\n",
    "    browse_button = tk.Button(root, text=\"Browse\", command=lambda: browse_file(file_entry))\n",
    "    browse_button.grid(row=0, column=3, padx=5, pady=5)\n",
    "    \n",
    "    format_label = tk.Label(root, text=\"File Format (Excel,Text,CSV):\", background='#E8F6EF')\n",
    "    format_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "    format_entry = tk.Entry(root, width=20)\n",
    "    format_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "    \n",
    "    support_label = tk.Label(root, text=\"Minimum Support Count:\", background='#E8F6EF')\n",
    "    support_label.grid(row=2, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "    support_entry = tk.Entry(root, width=20)\n",
    "    support_entry.grid(row=2, column=1, padx=5, pady=5)\n",
    "    \n",
    "    confidence_label = tk.Label(root, text=\"Minimum Confidence (%):\", background='#E8F6EF')\n",
    "    confidence_label.grid(row=3, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "    confidence_entry = tk.Entry(root, width=20)\n",
    "    confidence_entry.grid(row=3, column=1, padx=5, pady=5)\n",
    "    \n",
    "    percentage_label = tk.Label(root, text=\"Percentage of Data to Read:\", background='#E8F6EF')\n",
    "    percentage_label.grid(row=4, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "    percentage_entry = tk.Entry(root, width=20)\n",
    "    percentage_entry.grid(row=4, column=1, padx=5, pady=5)\n",
    "    \n",
    "    run_button = tk.Button(root, text=\"Run Analysis\", command=lambda: run_analysis(file_entry, format_entry, support_entry, confidence_entry, percentage_entry, output_text))\n",
    "    run_button.grid(row=5, column=1, padx=5, pady=5)\n",
    "    \n",
    "    output_frame = tk.Frame(root)\n",
    "    output_frame.grid(row=6, column=0, columnspan=4, padx=5, pady=5)\n",
    "    \n",
    "    output_text = tk.Text(output_frame, height=20, width=70)\n",
    "    output_text.pack(side=tk.LEFT, fill=tk.Y)\n",
    "    \n",
    "    scrollbar = ttk.Scrollbar(output_frame, orient=tk.VERTICAL, command=output_text.yview)\n",
    "    scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "    output_text.config(yscrollcommand=scrollbar.set)\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b565b-6206-4a0f-8e2a-76731aabee55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed03176-6779-4bc2-8570-2742c5e1ce30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
